{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (20.1)\n",
      "Requirement already up-to-date: scikit-image in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (2020.5.7)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: pooch>=0.5.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (2.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-image) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: imagecodecs>=2020.2.18 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from tifffile>=2019.7.26->scikit-image) (2020.2.18)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pooch>=0.5.2->scikit-image) (20.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pooch>=0.5.2->scikit-image) (2.20.0)\n",
      "Requirement already satisfied, skipping upgrade: appdirs in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pooch>=0.5.2->scikit-image) (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.1.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from packaging->pooch>=0.5.2->scikit-image) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->pooch>=0.5.2->scikit-image) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->pooch>=0.5.2->scikit-image) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->pooch>=0.5.2->scikit-image) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->pooch>=0.5.2->scikit-image) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (39.1.0)\n",
      "Requirement already up-to-date: ipympl in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.5.6)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipympl) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.7 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipympl) (4.8.2)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets>=7.5.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipympl) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib>=2.0.0->ipympl) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.10.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib>=2.0.0->ipympl) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib>=2.0.0->ipympl) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib>=2.0.0->ipympl) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib>=2.0.0->ipympl) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=4.0.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipykernel>=4.7->ipympl) (6.4.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipykernel>=4.7->ipympl) (4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: jupyter_client in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipykernel>=4.7->ipympl) (5.2.3)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipykernel>=4.7->ipympl) (5.0.2)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipywidgets>=7.5.0->ipympl) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipywidgets>=7.5.0->ipympl) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->ipympl) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->ipympl) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.15 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (1.0.15)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython_genutils in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel>=4.7->ipympl) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter_core in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from jupyter_client->ipykernel>=4.7->ipympl) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from jupyter_client->ipykernel>=4.7->ipympl) (17.0.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.4.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (5.5.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.0->ipympl) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.2.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel>=4.7->ipympl) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (5.4.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: mistune>=0.8.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (0.2.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (2.1.3)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (1.0)\n",
      "Requirement already satisfied, skipping upgrade: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.0->ipympl) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U scikit-image\n",
    "!pip install -U ipympl\n",
    "# For easier dev of local modules:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "\n",
    "# Initialize my ml_toolkit which is cloned to this instance\n",
    "path = os.path.abspath(os.path.join(os.path.dirname('../../..')))\n",
    "print(path)\n",
    "sys.path.append(path)\n",
    "from ml_toolkit.ml_toolkit import MLToolkit\n",
    "toolkit = MLToolkit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision I Final Project\n",
    "\n",
    "In this walkthrough, we will look at reading training, test data and creating a submission file for your final project. Once you train your model and get your predictions, submit your model's .csv output to the class [Leaderboard](https://leaderboard.corp.amazon.com/tasks/312)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up SageMaker\n",
    "\n",
    "Are your models taking too long to train? Use a P2 instance as described in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Access\n",
    "\n",
    "In this part, we will see how to read training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1588</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1321</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>669</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1674</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               data  label\n",
       "0  1588  [[[255, 255, 255], [255, 255, 255], [255, 255,...      4\n",
       "1  2011  [[[255, 255, 255], [255, 255, 255], [255, 255,...      1\n",
       "2  1321  [[[255, 255, 255], [255, 255, 255], [255, 255,...      4\n",
       "3   669  [[[255, 255, 255], [255, 255, 255], [255, 255,...      3\n",
       "4  1674  [[[255, 255, 255], [255, 255, 255], [255, 255,...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's read in our training data. ASINs correspond to those in Leaderboard's ID.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"/tmp/training_data.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e40aabb325441708cb25ee6a43eb36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4ab624a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see what kind of data we're working with\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(df['data'][90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labels correspondend to the following:\n",
    "\n",
    "* Class 0: *Inconclusive*\n",
    "* Class 1: *Two wheels*\n",
    "* Class 2: *Four wheels*\n",
    "* Class 3: *Not luggage*\n",
    "* Class 4: *Zero wheels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                    1221\n",
       "data     [[[255, 255, 255], [255, 255, 255], [255, 255,...\n",
       "label                                                    1\n",
       "Name: 90, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at this data in more detail and then start working. Remember 'label' is our target variable/column\n",
    "df.loc[90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Training 90% and Validation 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of train images: 1616\n",
      "no. of validation images: 180\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from mxnet import gluon\n",
    "\n",
    "train_percentage = 0.9\n",
    "\n",
    "# shuffling the dataframe\n",
    "#df = df.sample(frac=1)\n",
    "\n",
    "\n",
    "# # Splitting into training and validation subset\n",
    "train_indices = np.arange(0, int(train_percentage*len(df)))\n",
    "val_indices = np.arange(int(train_percentage*len(df)), len(df))\n",
    "\n",
    "train_df = df.iloc[train_indices]\n",
    "val_df = df.iloc[val_indices]\n",
    "\n",
    "# del df\n",
    "\n",
    "def getImages(images):\n",
    "    # Create the image holder array\n",
    "    image_arr = np.zeros((images.shape[0], 3, 224, 224), dtype=\"float32\")\n",
    "    extra_images = []\n",
    "    \n",
    "    # Iterate through the image data\n",
    "    for i, im in enumerate(images):\n",
    "        # Get image from the data column of the current row\n",
    "        \n",
    "        # We need a fixed size input, our images have different sizes, let's pick 224x224.\n",
    "        # Resize image below\n",
    "        im = resize(im, output_shape=(224, 224))\n",
    "        \n",
    "        # Gluon/mxnet expects images in this format (channel, row, column)\n",
    "        # This is the opposite of (row, column, channel), let's fix it\n",
    "        im = np.moveaxis(im, -1, 0)\n",
    "        \n",
    "        # Assign the value in the image array\n",
    "        image_arr[i] = im\n",
    "    return (image_arr)\n",
    "\n",
    "train_images, train_labels = getImages(train_df['data'].values), train_df['label'].values\n",
    "validation_images, validation_labels = getImages(val_df['data'].values), val_df['label'].values\n",
    "\n",
    "print('no. of train images: {}'.format(len(train_images)))\n",
    "print('no. of validation images: {}'.format(len(validation_images)))\n",
    "\n",
    "# Using Gluon Data loaders to load the data in batches\n",
    "train_dataset = gluon.data.ArrayDataset(train_images, train_labels)\n",
    "validation_dataset = gluon.data.ArrayDataset(validation_images, validation_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_train_images = np.array(train_images, copy=True)\n",
    "org_train_labels = np.array(train_labels, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of train images: 1616\n",
      "no. of train labels: 1616\n",
      "no. of validation images: 180\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(org_train_images, copy=True)\n",
    "train_labels = np.array(org_train_labels, copy=True)\n",
    "print('no. of train images: {}'.format(len(train_images)))\n",
    "print('no. of train labels: {}'.format(len(train_labels)))\n",
    "print('no. of validation images: {}'.format(len(validation_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "114\n",
      "no. of train images: 1730\n",
      "no. of train labels: 1730\n",
      "no. of validation images: 180\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flipped_images = []\n",
    "flipped_labels = []\n",
    "for idx, label in enumerate(train_labels):\n",
    "    if label in [0, 3]:\n",
    "        flipped_images.append(np.fliplr(train_images[idx]))\n",
    "        flipped_labels.append(label)\n",
    "#         flipped_images.append(np.flipud(train_images[idx]))\n",
    "#         flipped_labels.append(label)\n",
    "#         flipped_images.append(np.flip(train_images[idx], (0, 1)))\n",
    "#         flipped_labels.append(label)\n",
    "print(len(flipped_images))\n",
    "print(len(flipped_labels))\n",
    "train_images = np.concatenate((train_images, flipped_images))\n",
    "train_labels = np.concatenate((train_labels, flipped_labels))\n",
    "print('no. of train images: {}'.format(len(train_images)))\n",
    "print('no. of train labels: {}'.format(len(train_labels)))\n",
    "print('no. of validation images: {}'.format(len(validation_images)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156 657 500  72 345]\n",
      "[0.22745664 0.1550578  0.17774567 0.23959537 0.20014451]\n"
     ]
    }
   ],
   "source": [
    "# Weighting\n",
    "no_samples_per_label = np.zeros(5, dtype=\"int\")\n",
    "for label in train_labels:\n",
    "    no_samples_per_label[label] = no_samples_per_label[label]+1\n",
    "print(no_samples_per_label)\n",
    "weights = np.zeros(5, dtype=\"float32\")\n",
    "for i, n in enumerate(no_samples_per_label):\n",
    "    weights[i] = (1-(n/len(train_images)))/4\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gluon Data loaders to load the data in batches\n",
    "train_dataset = gluon.data.ArrayDataset(train_images, train_labels)\n",
    "validation_dataset = gluon.data.ArrayDataset(validation_images, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd9a2b07ac348dfa78fbe945368edda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toolkit.draw_class_distribution(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#     Class 0: Inconclusive\n",
    "#     Class 1: Two wheels\n",
    "#     Class 2: Four wheels\n",
    "#     Class 3: Not luggage\n",
    "#     Class 4: Zero wheels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in ['Inconclusive', 'Two wheels', 'Four wheels', 'Not luggage', 'Zero wheels']], columns = [i for i in ['Inconclusive', 'Two wheels', 'Four wheels', 'Not luggage', 'Zero wheels']])\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    plt.title('Validation Confusion Matrix')\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def setup_drawing_widget():\n",
    "    out1 = widgets.Output()\n",
    "    out2 = widgets.Output()\n",
    "    with out1: \n",
    "        fig = plt.figure()\n",
    "        ax = fig.subplots(1)\n",
    "        plt.title('Validation Confusion Matrix')\n",
    "        fig.canvas.toolbar_visible = False\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.canvas.footer_visible = False\n",
    "        fig.canvas.resizable = False\n",
    "    return (out1, fig, out2)\n",
    "    \n",
    "def plot_confusion_matrix(text_string, y_true, y_pred):\n",
    "    fig.clear()\n",
    "    ax = fig.subplots(1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in ['Inconclusive', 'Two wheels', 'Four wheels', 'Not luggage', 'Zero wheels']], columns = [i for i in ['Inconclusive', 'Two wheels', 'Four wheels', 'Not luggage', 'Zero wheels']])\n",
    "    plt.title('Validation Confusion Matrix')\n",
    "    plt.suptitle(text_string, fontsize=8)\n",
    "    sn.heatmap(df_cm, annot=True, ax = ax)\n",
    "    fig.canvas.draw()\n",
    "    with out2:\n",
    "        print(text_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ml_toolkit.ml_toolkit import MLToolkit\n",
    "toolkit = MLToolkit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, ndarray\n",
    "from mxnet.gluon.loss import SoftmaxCrossEntropyLoss\n",
    "import mxnet.ndarray as nd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "def train(weights):\n",
    "    # Set this to CPU or GPU depending on your training instance\n",
    "    # ctx = mx.cpu()\n",
    "    ctx = mx.gpu()\n",
    "\n",
    "    # Hyper-paramaters of the system\n",
    "    batch_size = 64\n",
    "    #epochs = 150\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Weighing\n",
    "    #weights = nd.array([0.23,0.15,0.18,0.24,0.20])\n",
    "    weights = nd.array(weights)\n",
    "\n",
    "    # Create the network. We have 5 classes\n",
    "    num_outputs = 5\n",
    "\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        net.add(gluon.nn.Conv2D(channels=60, kernel_size=3, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        # The Flatten layer collapses all axis, except the first one, into one axis.\n",
    "        net.add(gluon.nn.Flatten())\n",
    "        net.add(gluon.nn.Dense(512, activation=\"relu\"))\n",
    "        net.add(gluon.nn.Dense(num_outputs))\n",
    "\n",
    "    # Initialize parameters\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "\n",
    "    # Define loss and trainer.\n",
    "    softmax_cross_etropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate})\n",
    "\n",
    "    train_loader = gluon.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = gluon.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Starting the outer loop, we will have 3 epochs (3 full pass through our dataset)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Training loop: (with autograd and trainer steps, etc.)\n",
    "        # This loop does the training of the neural network (weights are updated)\n",
    "        cumulative_train_loss = 0\n",
    "        train_predictions = []\n",
    "        for i, (data, label) in enumerate(train_loader):\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            w = weights.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                train_predictions = train_predictions + np.argmax(output.asnumpy(), axis=1).tolist()\n",
    "                loss = softmax_cross_etropy_loss(output, label, w)\n",
    "                cumulative_train_loss = cumulative_train_loss + nd.sum(loss)\n",
    "            loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "\n",
    "        # Calculating the Softmax Cross Entopy Loss for training\n",
    "        train_loss = cumulative_train_loss/len(train_images)\n",
    "\n",
    "        # Validation loop:\n",
    "        # This loop tests the trained network on validation dataset\n",
    "        # No weight updates here\n",
    "        cumulative_valid_loss = 0\n",
    "        val_predictions = []\n",
    "        for i, (data, label) in enumerate(validation_loader):\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            w = weights.as_in_context(ctx)\n",
    "            output = net(data)\n",
    "            val_predictions = val_predictions + np.argmax(output.asnumpy(), axis=1).tolist()\n",
    "            val_loss = softmax_cross_etropy_loss(output, label, w)\n",
    "            cumulative_valid_loss = cumulative_valid_loss + nd.sum(val_loss)\n",
    "        valid_loss = cumulative_valid_loss/len(validation_images)\n",
    "\n",
    "        # Calculate training and validation accuracies\n",
    "        # I used a accuracy_score() function from the sklearn library here. \n",
    "        # accuracy = (TP+TN) / (TP+FP+TN+FN)\n",
    "        train_accuracy = accuracy_score(train_labels.tolist(), train_predictions)\n",
    "        validation_accuracy = accuracy_score(validation_labels.tolist(), val_predictions)\n",
    "\n",
    "        # Print the summary and plot the confusion matrix after each epoch\n",
    "    #     print(\"Epoch {}, training loss: {:.2f}, validation loss: {:.2f}, training accuracy: {:.2f}, validation accuracy: {:.2f}\".format(epoch, train_loss.asnumpy()[0], valid_loss.asnumpy()[0], train_accuracy, validation_accuracy))\n",
    "    #     if epoch % 5 == 0 and epoch != 0:\n",
    "    #         plot_confusion_matrix(validation_labels.tolist(), val_predictions)\n",
    "        text_string = \"Epoch {}, training loss: {:.2f}, validation loss: {:.2f}, training accuracy: {:.2f}, validation accuracy: {:.2f}\".format(epoch, train_loss.asnumpy()[0], valid_loss.asnumpy()[0], train_accuracy, validation_accuracy)\n",
    "        #toolkit.plot_confusion_matrix(text_string, validation_labels.tolist(), val_predictions)\n",
    "        toolkit.set_confusion_matrix(epoch, text_string, validation_labels.tolist(), val_predictions)\n",
    "        toolkit.write_epochs(text_string)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this must be called before the training started so that we have the widget\n",
    "out1, fig, out2 = setup_drawing_widget()\n",
    "tab = widgets.Tab(children = [out1, out2])\n",
    "tab.set_title(0, 'Validation Confusion Matrix')\n",
    "tab.set_title(1, 'Output')\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0e6c6ee2db47308a0980ef8dd08340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), _titles={'0': 'Validation Confusion Matrix', '1': 'Output'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toolkit.prepare_training_widget(no_of_epochs=epochs)\n",
    "toolkit.display_training_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're unsure of how to submit to Leaderboard, no problemo.You'll use the training file loaded above to make your ML model and then predict on the files below:\n",
    "\n",
    "test_df = pd.read_pickle(\"/tmp/test_data.pkl\")\n",
    "plt.imshow(test_df['data'][90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample zero submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is an example submission of a very poor model\n",
    "\n",
    "test_submission = pd.read_csv('/tmp/sample_model_output.csv', header=0)\n",
    "test_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = getImages(test_df[\"data\"].values)\n",
    "test_loader = gluon.data.DataLoader(test_images, batch_size=batch_size)\n",
    "\n",
    "test_predictions = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    data = data.as_in_context(ctx)\n",
    "    output = net(data)\n",
    "    test_predictions = test_predictions + np.argmax(output.asnumpy(), axis=1).tolist()\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "result_df = pd.DataFrame(columns=['ID', 'label'])\n",
    "result_df[\"ID\"] = test_df[\"ID\"]\n",
    "# Get your model's predictions when submitting (not the zero submission here)\n",
    "result_df[\"label\"] = test_predictions #test_submission['label'].values\n",
    "\n",
    "result_df.to_csv(\"results_cv_project.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you navigate to the day1/results folder in the Jupyter file browser, you can select the results_cv_project.csv and dowload it locally. Or just click this [link...](./results_cv_project.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our model output into Leaderboard\n",
    "\n",
    "We now have our model's output .csv and are ready to upload to Leaderboard\n",
    "1. Go to your class [Leaderboard instance](https://leaderboard.corp.amazon.com/tasks/312) and go to the 'Make a Submission' section\n",
    "2. Upload your local file and include your notebook version URL for tracking\n",
    "3. Your score on the public leaderboard should now appear. Marvel on how much room for improvement there is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
